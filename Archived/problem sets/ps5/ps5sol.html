<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<title>EE 460N: Problem Set 5 Solution</title>
<link rel="StyleSheet" type="text/css" href="../../main.css" />
<link rel="StyleSheet" type="text/css" href="../probs.css" />
</head>
<body>
<center>
<h2>
Department of Electrical and Computer Engineering</h2></center>

<center>
<h3>The University of Texas at Austin</h3></center>
EE 460N, Spring 2011
<br />Problem Set 5 Solution
<br />Yale N. Patt, Instructor
<br />Faruk Guvenilir, Milad Hashemi, Yuhao Zhu, TAs 

<ol class="questions">

<li><!-- Begin Question -->
<ol>
  <li>-3.25
  </li>
  <li>1.25 x 2^(-128)
  </li>
  <li>Negative Infinity
  </li>
</ol>
</li><!-- End of Question -->

<li><!-- Begin Question -->
<p>An 8KB cache size with a 8B line size, in a 4-way set associative
cache means there are <span class="equation">8KB &divide; (4 &times; 8B) = 256</span> sets in the cache.</p>
<p>Since there are 256 or 2<sup>8</sup> sets, 8 bits are required to index
into the correct set. Since there are 8B or 2<sup>3</sup> bytes in a cache line,
3 bits are required to find the correct byte within a block. Given a 24-bit address space, this leaves <span class="equation">24 - 8 - 3 = 13</span> bits left
over for the tag store. Additionally, the tag store must hold 2 bits
for the V/NV replacement policy and 1 valid bit. This means each cache
line must have a 16-bit tag store associated with it. 2B of tag store
times (256 &times; 4) cache lines in the cache means that the tag store, in total
takes up 2048 bytes, which is <span class="answer">16384 bits</span></p>
</li><!-- End Question -->

<li><!-- Begin Question -->
<p>The size of the tag store is <span class="equation">2<sup>12</sup> + 2<sup>8</sup></span>. We know that the size of 
the tag store can be given as the product of number of sets and number of bits per set.</p>
<p>We also know that address space is 16-bits. Hence,
<span class="equation"><var>tag</var> + <var>index</var> + <var><abbr title="Byte within block">bib</abbr></var> = 16</span></p>
<p>In order to find <var>bib</var>, we need to find <var>index</var> and <var>tag</var>.
The following bits are necessary for each set of the tag store:</p>
<ul>
<li>1 bit for LRU (remember: you only need one bit per set for a 2-way associative cache)</li>
<li>2 valid bits</li>
<li>2 dirty bits</li>
<li>2 &times; <var>tag</var> tag bits</li>
</ul>
<p>Total number of bits per set is <span class="equation">5 + 2 &times; <var>tag</var></span>. An important conclusion that can be drawn is that number of bits per set will always 
be an odd number.</p>
<p>We will also use the fact that number of sets is always a power of 2 (since it is 
indexed using an integer number of bits). Given the size of the tag store, <var>index</var> has 
to be a number less than 8 (the size of the tag store is indivisible by 2<sup>9</sup> or greater).</p>
<p>The only value of <var>index</var> that fits both criterion is 8. Therefore:</p>

<div class="equation">Number of sets = 2<sup>8</sup> = 256</div>
<div class="equation">Bits per row = 4352 &divide; 256 = 17</div>
<div class="equation">17 = 5 + 2 &times; <var>tag</var> &rArr; <var>tag</var> = 6</div>
<div class="equation">6 + 8 + <var>bib</var> = 16 &rArr; <var>bib</var> = 2</div>
<p>Hence, the cache block size is <span class="answer">4 bytes</span></p>
</li><!-- End Question -->

<li><!-- Begin Question -->
<div class="equation"><var>average_access_time_per_instruction</var>
= 1 &times; instruction_access_time + 0.3 &times; data_access_time</div>

<p>We can use the following equations in both part a and part b to compute 
the instruction and data access time.</p>

<div class="equation"><var>instruction_access_time</var> = 1 + 0.05 &times; (6 + 0.15 &times; mem_latency)</div>
<div class="equation"><var>data_access_time</var> = 1 + 0.10 &times; (6 + 0.25 &times; mem_latency)</div>

<ol>
<li>
<p>We need to calculate the memory latency. Since each cache block is 8 
words, it will take 8 accesses to get a cache block from memory.</p>
<pre>    
(-)(...)(-)
        (-)(...)(-)
                (-)(...)(-)
                        (-)(...)(-)
                                (-)(...)(-)
                                        (-)(...)(-)
                                                (-)(...)(-)
                                                        (-)(...)(-)

|&lt;---------------------- 169 cycles -----------------------------&gt;|
</pre>

<p>Using the equations, we get 2.5675 cycles for <var>instruction_access_time</var> and 
5.825 for <var>data_access_time</var>.</p>

<p>The average latency is <span class="equation">2.5675 + 0.3 &times; 5.825 = <span class="answer">4.315 cycles</span></span></p>
</li>
<li>
<p>We again need to compute the memory latency:</p>
<pre>
(-)(.............)(-)
   (-)(.............)(-)
      (-)(.............)(-)
         (-)(.............)(-)
                  (-)(...........)(-)
                     (-)(...........)(-)
                        (-)(...........)(-)
                           (-)(...........)(-)

|&lt;--------21-----&gt;&lt;1&gt;&lt;-----20----&gt;&lt;---- 4 ---&gt;|
</pre>
<p>So the mem_latency is 46 cycles. Again using the equations, the 
instruction_access_time is 1.645 and data_acces_time is 2.75.</p>

<p>The average latency is <span class="equation">1.645 + 2.75 &times; 0.3 = <span class="answer">2.47 cycles</span></span></p>
</li>
<p> 
<li>
<p> We need to compute memory latency for 8-way interleaving
<pre>
(-)(.............)(-)
   (-)(.............)(-)
      (-)(.............)(-)
         (-)(.............)(-)
            (-)(...........)(-)
               (-)(...........)(-)
                  (-)(...........)(-)
                     (-)(...........)(-)
|--------21-------|--------8-----------|
</pre>
<p> So memory latency is 29 cycles. Using the equations, we get
    the instruction_access_time as 1.517 and data_acces_time as 2.325.
<p> The average latency is 1.517 + .3 * 2.325 = 2.215
</li>
<li>
<p>The improvement is <span class="equation">(4.315 - 2.47) &divide; 4.315 = 0.4276</span> Therefore, the average latency improves by <span class="answer">42.76%</span></p>
</li>
</ol>
</li><!-- End Question -->

<li><!-- Begin Question -->
We assume that the address is 12 bits (we could also have assumed a
10-bit address)
<ol type="a">
<li>The address is divided into 3 portions:
<ul>
<li>address[1:0] (2 bits) for the byte in the block</li>
<li>address [4:2] (3 bits) for the cache index</li>
<li>address[11:5] (7 bits) for the tag</li>
</ul>
<p>The contents of the cache at the end of each pass are the same. They are
shown below:</p>
<table>
<tr><th>Valid</th><th>Tag</th><th colspan="4">Data (addresses are written inside each byte)</th></tr>
<tr><td>1</td><td>0010 000</td><td>203</td><td>202</td><td>201</td><td>200</td></tr>
<tr><td>1</td><td>0010 000</td><td>207</td><td>206</td><td>205</td><td>204</td></tr>
<tr><td>1</td><td>0010 000</td><td>20B</td><td>20A</td><td>209</td><td>208</td></tr>
<tr><td>1</td><td>0010 010</td><td>24F</td><td>24E</td><td>24D</td><td>24C</td></tr>
<tr><td>1</td><td>0010 111</td><td>2F3</td><td>2F2</td><td>2F1</td><td>2F0</td></tr>
<tr><td>1</td><td>0010 111</td><td>2F7</td><td>2F6</td><td>2F5</td><td>2F4</td></tr>
<tr><td>1</td><td>0010 000</td><td>21B</td><td>21A</td><td>219</td><td>218</td></tr>
<tr><td>1</td><td>0010 000</td><td>21F</td><td>21E</td><td>21D</td><td>21C</td></tr>
</table>

<p>The hit/miss information for each pass is shown below:</p>
<table>
<tr><th>Reference</th><td>200</td><td>204</td><td>208</td><td>20C</td><td>2F4</td><td>2F0</td><td>200</td><td>204</td><td>218</td><td>21C</td><td>24C</td><td>2F4</td></tr>
<tr><th>Pass 1:</th><td>M</td><td>M</td><td>M</td><td>M</td><td>M</td><td>M</td><td>H</td><td>H</td><td>M</td><td>M</td><td>M</td><td>H</td></tr>
<tr><th>Pass 2:</th><td>H</td><td>H</td><td>H</td><td>M</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>M</td><td>H</td></tr>
<tr><th>Pass 3:</th><td>H</td><td>H</td><td>H</td><td>M</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>M</td><td>H</td></tr>
<tr><th>Pass 4:</th><td>H</td><td>H</td><td>H</td><td>M</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>M</td><td>H</td></tr>
</table>
<p>Hit rate is <span class="answer">33/48</span></p>
</li>
<li>
<p>The address is divided into two: 2 bits for identifying
the byte in the block, 10 bits for the tag. No bits are needed for
cache index. The following table shows the contents of the cache at the end of each pass (Valid
bits and Tags are ignored, they should be obvious. Starting addresses
of blocks in the cache are provided):</p>
<table>
<thead>
<tr><th>Pass</th><th>Way 0 Data</th><th>Way 1 Data</th><th>Way 2 Data</th><th>Way 3 Data</th><th>Way 4 Data</th><th>Way 5 Data</th><th>Way 6 Data</th><th>Way 7 Data</th></tr>
</thead>
<tbody>
<tr><td>1</td><td>200</td><td>204</td><td>24C</td><td>20C</td><td>2F4</td><td>2F0</td><td>218</td><td>21C</td></tr>
<tr><td>2</td><td>200</td><td>204</td><td>21C</td><td>24C</td><td>2F4</td><td>20C</td><td>2F0</td><td>218</td></tr>
<tr><td>3</td><td>200</td><td>204</td><td>218</td><td>21C</td><td>2F4</td><td>24C</td><td>20C</td><td>2F0</td></tr>
<tr><td>4</td><td>200</td><td>204</td><td>2F0</td><td>218</td><td>2F4</td><td>21C</td><td>24C</td><td>20C</td></tr>
</tbody>
</table>

<p>The hit/miss information for each pass is shown below:</p>
<table>
<tr><th>Reference:</th><td>200</td><td>204</td><td>208</td><td>20C</td><td>2F4</td><td>2F0</td><td>200</td><td>204</td><td>218</td><td>21C</td><td>24C</td><td>2F4</td></tr>
<tr><th>Pass 1:</th><td>M</td><td>M</td><td>M</td><td>M</td><td>M</td><td>M</td><td>H</td><td>H</td><td>M</td><td>M</td><td>M</td><td>H</td></tr>
<tr><th>Pass 2:</th><td>H</td><td>H</td><td>M</td><td>M</td><td>H</td><td>M</td><td>H</td><td>H</td><td>M</td><td>M</td><td>M</td><td>H</td></tr>
<tr><th>Pass 3:</th><td>H</td><td>H</td><td>M</td><td>M</td><td>H</td><td>M</td><td>H</td><td>H</td><td>M</td><td>M</td><td>M</td><td>H</td></tr>
<tr><th>Pass 4:</th><td>H</td><td>H</td><td>M</td><td>M</td><td>H</td><td>M</td><td>H</td><td>H</td><td>M</td><td>M</td><td>M</td><td>H</td></tr>
</table>
<p>Hit rate is <span class="answer">21/48</span></p>
</li>
<li>
<p>The address is divided into 3 portions: 2 bits for
identifying the byte in the block, 1 bit for the cache index, 9 bits
for the tag. The contents of the cache at the end of Pass 1:</p>

<table>
<thead>
<tr><th colspan="3">Way 0</th><th colspan="3">Way 1</th><th colspan="3">Way 2</th><th colspan="3">Way 3</th></tr>
<tr><th>V</th><th>Tag</th><th>Data</th><th>V</th><th>Tag</th><th>Data</th><th>V</th><th>Tag</th><th>Data</th><th>V</th><th>Tag</th><th>Data</th></tr>
</thead>
<tbody>
<tr><td>1</td><td>0010 0000 0</td><td>203-200</td><td>1</td><td>0010 0000 1</td><td>20B-208</td><td>1</td><td>0010 1111 0</td><td>2F3-2F0</td><td>1</td><td>0010 0001 1</td><td>21B-218</td></tr>
<tr><td>1</td><td>0010 0000 0</td><td>207-204</td><td>1</td><td>0010 0100 1</td><td>24F-24C</td><td>1</td><td>0010 1111 0</td><td>2F7-2F4</td><td>1</td><td>0010 0001 1</td><td>21F-21C</td></tr>
</tbody>
</table>

<p>The hit/miss information for each pass is shown below:</p>

<table>
<tr><th>Reference:</th><td>200</td><td>204</td><td>208</td><td>20C</td><td>2F4</td><td>2F0</td><td>200</td><td>204</td><td>218</td><td>21C</td><td>24C</td><td>2F4</td></tr>
<tr><th>Pass 1:</th><td>M</td><td>M</td><td>M</td><td>M</td><td>M</td><td>M</td><td>H</td><td>H</td><td>M</td><td>M</td><td>M</td><td>H</td></tr>
<tr><th>Pass 2:</th><td>H</td><td>H</td><td>H</td><td>M</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>M</td><td>M</td><td>H</td></tr>
<tr><th>Pass 3:</th><td>H</td><td>H</td><td>H</td><td>M</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>M</td><td>M</td><td>H</td></tr>
<tr><th>Pass 4:</th><td>H</td><td>H</td><td>H</td><td>M</td><td>H</td><td>H</td><td>H</td><td>H</td><td>H</td><td>M</td><td>M</td><td>H</td></tr>
</table>

<p>Contents of the second set of the cache (index equals 1) after pass 2, 3, and 4 (the first set remains the same):</p>
<table>
<thead>
<tr><th rowspan="2">Pass</th><th colspan="3">Way 0</th><th colspan="3">Way 1</th><th colspan="3">Way 2</th><th colspan="3">Way 3</th></tr>
<tr><th>V</th><th>Tag</th><th>Data</th><th>V</th><th>Tag</th><th>Data</th><th>V</th><th>Tag</th><th>Data</th><th>V</th><th>Tag</th><th>Data</th></tr>
</thead>
<tbody>
<tr><td>2</td><td>1</td><td>0010 0000 0</td><td>207-204</td><td>1</td><td>0010 0001 1</td><td>21F-21C</td><td>1</td><td>0010 1111 0</td><td>2F7-2F4</td><td>1</td><td>0010 0100 1</td><td>24F-24C</td></tr>
<tr><td>3</td><td>1</td><td>0010 0000 0</td><td>207-204</td><td>1</td><td>0010 0100 1</td><td>24F-24C</td><td>1</td><td>0010 1111 0</td><td>2F7-2F4</td><td>1</td><td>0010 0001 1</td><td>21F-21C</td></tr>
<tr><td>4</td><td>1</td><td>0010 0000 0</td><td>207-204</td><td>1</td><td>0010 0001 1</td><td>21F-21C</td><td>1</td><td>0010 1111 0</td><td>2F7-2F4</td><td>1</td><td>0010 0100 1</td><td>24F-24C</td></tr>
</tbody>
</table>

<p>Hit Rate is <span class="answer">30/48</span></p>
</li>
</ol>
</li><!-- End Question -->



<li><!-- Begin Question -->
<h3>Block Size</h3>
<p>The following table lists hit ratios for different cache block sizes given the access sequence 1 (0, 2, 4, 8, 16, 32):</p>
<table>
<thead>
<tr><th>Block Size</th><th>Hit Ratio</th></tr>
</thead>
<tbody>
<tr><td>1B</td><td>0/6</td></tr>
<tr><td>2B</td><td>0/6</td></tr>
<tr><td>4B</td><td>1/6</td></tr>
<tr><td>8B</td><td>2/6</td></tr>
<tr><td>16B</td><td>3/6</td></tr>
<tr><td>32B</td><td>4/6</td></tr>
</tbody>
</table>
<p>Since the hit ratio is reported as 0.33 for this sequence, the block size 
must be <span class="answer">8 bytes</span>. Therefore, the accesses look like this:</p>
<table>
<tr><th>Address</th><td>0</td><td>2</td><td>4</td><td>8</td><td>16</td><td>32</td></tr>
<tr><th>Hit/Miss</th><td>M</td><td>H</td><td>H</td><td>M</td><td>M</td><td>M</td></tr>
</table>
<h3>Associativity</h3>
<p>Notice that all of the addresses of sequence 2 (0, 512, 1024, 1536, 2048, 1536, 1024, 512, 0) are multiples of 512. This means that they all map to the same set, since the size of the cache can only be 256 or 512 bytes. Therefore, the hit ratio would be 0/9 in case of a direct-mapped cache. In case of a 2-way cache, the accesses would behave as follows:</p>
<table>
<tr><th>Address</th><td>0</td><td>512</td><td>1024</td><td>1536</td><td>2048</td><td>1536</td><td>1024</td><td>512</td><td>0</td></tr>
<tr><th>Hit/Miss</th><td>M</td><td>M</td><td>M</td><td>M</td><td>M</td><td>H</td><td>M</td><td>M</td><td>M</td></tr>
</table>
<p>The resulting hit rate would be 1/9. Similarly, for 4-way cache:</p>
<table>
<tr><th>Address</th><td>0</td><td>512</td><td>1024</td><td>1536</td><td>2048</td><td>1536</td><td>1024</td><td>512</td><td>0</td></tr>
<tr><th>Hit/Miss</th><td>M</td><td>M</td><td>M</td><td>M</td><td>M</td><td>H</td><td>H</td><td>H</td><td>M</td></tr>
</table>
<p>The resulting hit rate would be 3/9, and thus the cache is <span class="answer">4-way set associative</span>.</p>
<h3>Cache Size</h3>
<p>If the cache size were 256B, there would be 3 index bits and all of the adresses in sequence 3 (0, 64, 128, 256, 512, 256, 128, 64, 0) would map to the same set:</p>
<table>
<tr><th>Address</th><td>0</td><td>64</td><td>128</td><td>256</td><td>512</td><td>256</td><td>128</td><td>64</td><td>0</td></tr>
<tr><th>Hit/Miss</th><td>M</td><td>M</td><td>M</td><td>M</td><td>M</td><td>H</td><td>H</td><td>H</td><td>M</td></tr>
</table>
<p>The resulting hit ratio would be 3/9, and thus the cache size is <span class="answer">256B</span>.
For completeness, here's how the accesses would look like in case of a 512B cache (4 index bits):</p>
<table>
<tr><th>Address</th><td>0</td><td>64</td><td>128</td><td>256</td><td>512</td><td>256</td><td>128</td><td>64</td><td>0</td></tr>
<tr><th>Hit/Miss</th><td>M</td><td>M</td><td>M</td><td>M</td><td>M</td><td>H</td><td>H</td><td>H</td><td>H</td></tr>
</table>
<h3>Replacement Policy</h3>
<p>In case of the FIFO replacement policy, the accesses of sequence 3 (0, 512, 1024, 0, 1536, 0, 2048, 512) would look as follows:</p>
<table>
<tr><th>Address</th><td>0</td><td>512</td><td>1024</td><td>0</td><td>1536</td><td>0</td><td>2048</td><td>512</td></tr>
<tr><th>Hit/Miss</th><td>M</td><td>M</td><td>M</td><td>H</td><td>M</td><td>H</td><td>M</td><td>H</td></tr>
</table>
<p>The resulting hit ration would be 3/8. However, in case of the LRU replacement policy the hit rate would be 0.25:</p>
<table>
<tr><td>0</td><td>512</td><td>1024</td><td>0</td><td>1536</td><td>0</td><td>2048</td><td>512</td></tr>
<tr><td>M</td><td>M</td><td>M</td><td>H</td><td>M</td><td>H</td><td>M</td><td>M</td></tr>
</table>
<p>Thus the replacement policy is <span class="answer">LRU</span>.</p>
</li><!-- End Question -->

<li><font color="red" size="-1">Question Postponed.</font></li>
<li><font color="red" size="-1">Question Postponed.</font></li>

<li><!-- Begin Question -->
<p>The state diagram for the FSM device controller can be found in the
handouts section of the website under the notes for I/O.  Note that in the
notes, the transition from BGout to IDLE is based on the SACK signal.  This is
to illustrate the second race condition which is corrected by basing the
transition on (NOT BGin).</p>
<!--<img src="ps3q1x.gif" alt="The device controller state diagram" />-->
<p>The input and output signals of the controller are:</p>
<table>
<thead>
<tr><th>Signal</th><th>Type</th><th>Function</th></tr>
</thead>
<tbody>
<tr>
<td>DEV</td><td>Input</td>
<td>Asserted when the device needs to initiate a bus transaction</td>
</tr>
<tr>
<td>BG<sub>in</sub></td><td>Input</td>
<td>Incoming bus grant signal, asserted by the priority arbitration unit</td>
</tr>
<tr>
<td>BBSY<sub>in</sub></td><td>Input</td>
<td>Asserted by the current bus master. Negative edge indicates the end of a bus cycle.</td>
</tr>
<tr>
<td>MSYN</td><td>Input</td>
<td>Master-side handshaking signal that controls the bus transaction between the bus master and the slave</td>
</tr>
<tr>
<td>SSYN</td><td>Input</td>
<td>Slave-side handshaking signal that controls the bus transaction between the bus master and the slave</td>
</tr>
<tr>
<td>BR<sub>out</sub></td><td>Output</td>
<td>Asserted to request the bus. Goes to the priority arbitration unit.</td>
</tr>
<tr>
<td>SACK</td><td>Output</td>
<td>Asserted by the device that has won the arbitration</td>
</tr>
<tr>
<td>BBSY<sub>out</sub></td><td>Output</td>
<td>Same as BBSY<sub>in</sub></td>
</tr>
<tr>
<td>BG<sub>out</sub></td><td>Output</td>
<td>Asserted when the controller needs to pass the bus grant signal down the daisy chain.</td>
</tr>
</tbody>
</table>

<p>Two race conditions are:</p>
<ol>
<li>
<p>This race condition is subtle. From the PAU side the PAU asserts BGj, which
works its way down the daisy chain to all devices at BRj. Before SACK is
asserted, a controller asserts BRk, where k is higher priority than j. PAU now
asserts BGk, and you have two BG signals propagating, which will result in two
controllers thinking they are the next bus master.</p>

<p>Solution: PAU latches BR signals when it sees NOT-BBSY, indicating it is
okay to grant the bus again. NOT-SACK is also gated (after sufficient delay)
with the BG signals, guaranteeing that a BG signal cannot be asserted until
after PAU logic has taken effect. Any subsequent BR signal does not get latched
and so can not affect the PAU logic.</p>
</li> 

<li>
<p>Let's say device controller D1 is in BG<sub>out</sub> state. This means that
some device D2 that is down the same daisy chain as D1 had requested and is
granted the bus. Let's say the device of D1 asserts the DEV signal while D1 is
in BG<sub>out</sub> state. D2 will eventually receive the BG<sub>in</sub>
signal and transition to the SACK state. It will take some time for the SACK
signal to travel to the priority arbitration unit. The SACK signal probably
reaches D1 before it reaches the priority arbitration unit. Hence, when the
SACK signal reaches D1 the BG<sub>in</sub> input of D1 is still being asserted.
Therefore, upon receiving the SACK signal D1 will immediately transition to
IDLE to BR<sub>out</sub> to SACK states. Hence, both D1 and D2 will be
asserting the SACK signal which is not desirable. A simple solution that fixes
this race condition is not transitioning to IDLE state if the BG<sub>in</sub>
signal is still high.</p>
</li>

</ol>
</li><!-- End of Question -->

<li><!-- Begin Question -->
<ol type="a">
<li>
<p>The solution is shown below:</p>
<img src="prob5a.jpg" alt="The bus logic diagram" />
</li>
<li>
<p>It is possible. Consider a case where device 3 and 4 just alternate the bus.</p>
</li>
<li>
<p>The solution is shown below.</p>
<img src="prob5c-new.jpg" alt="The device controller state machine" /> 
</li>
</ol>
</li><!-- End of Question -->

</li>
</ol>
</body>
</html>
